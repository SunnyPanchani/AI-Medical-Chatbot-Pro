{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Medical Chatbot Development Notebook\n",
    "## Using LangChain 1.0 + Groq + Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb4646cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9efc022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\code\\\\1-Github\\\\AI Medical Chatbot Pro\\\\research'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab041165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fc92ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\code\\\\1-Github\\\\AI Medical Chatbot Pro'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5fcdc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\envs\\medibot\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Modern imports - Compatible with LangChain 1.0+\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7d10d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_files(data):\n",
    "    \"\"\"Load all PDF files from directory\"\"\"\n",
    "    loader = DirectoryLoader(data, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f78f067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 637 documents\n"
     ]
    }
   ],
   "source": [
    "# Load PDFs from data folder\n",
    "extracted_docs = load_pdf_files('data')\n",
    "print(f\"Loaded {len(extracted_docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b65aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def filter_to_minimal_docs(docs: List[Document]) -> List[Document]:\n",
    "    \"\"\"Keep only essential metadata\"\"\"\n",
    "    minimal_docs: List[Document] = []\n",
    "    for doc in docs:\n",
    "        src = doc.metadata.get('source')\n",
    "        minimal_docs.append(\n",
    "            Document(page_content=doc.page_content, metadata={'source': src})\n",
    "        )\n",
    "    return minimal_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aced9c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to 637 minimal documents\n"
     ]
    }
   ],
   "source": [
    "minimal_docs = filter_to_minimal_docs(extracted_docs)\n",
    "print(f\"Filtered to {len(minimal_docs)} minimal documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9805f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(minimal_docs):\n",
    "    \"\"\"Split documents into chunks\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20\n",
    "    )\n",
    "    texts_chunk = text_splitter.split_documents(minimal_docs)\n",
    "    return texts_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f02477dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 5859 chunks\n"
     ]
    }
   ],
   "source": [
    "texts_chunk = text_split(minimal_docs)\n",
    "print(f\"Split into {len(texts_chunk)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81c5bb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_13208\\945296939.py:7: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=model_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embeddings model loaded\n"
     ]
    }
   ],
   "source": [
    "# Initialize embeddings model\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def download_embeddings():\n",
    "    \"\"\"Initialize HuggingFace embeddings\"\"\"\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "    return embeddings\n",
    "\n",
    "embedding = download_embeddings()\n",
    "print(\"✅ Embeddings model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db262a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Test embeddings\n",
    "vectors = embedding.embed_query(\"Hello world\")\n",
    "print(f\"Vector dimension: {len(vectors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "281c578b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Environment variables loaded\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "print(\"✅ Environment variables loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d83bca55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pinecone API key loaded\n",
      "✅ Groq API key loaded\n"
     ]
    }
   ],
   "source": [
    "# Get API keys from environment (SECURE WAY)\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "if not PINECONE_API_KEY:\n",
    "    print(\"❌ PINECONE_API_KEY not found\")\n",
    "else:\n",
    "    print(\"✅ Pinecone API key loaded\")\n",
    "    \n",
    "if not GROQ_API_KEY:\n",
    "    print(\"❌ GROQ_API_KEY not found\")\n",
    "else:\n",
    "    print(\"✅ Groq API key loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ef078d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to Pinecone\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "print(\"✅ Connected to Pinecone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b1eeba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Index 'medical-chatbot' already exists\n"
     ]
    }
   ],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "index_name = \"medical-chatbot\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    print(f\"Creating index '{index_name}'...\")\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "    print(\"✅ Index created\")\n",
    "else:\n",
    "    print(f\"✅ Index '{index_name}' already exists\")\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ab676e",
   "metadata": {},
   "source": [
    "## Check if Documents Already Exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d68a2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vector store...\n",
      "✅ Vector store created\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# Check if vectors already exist\n",
    "index_stats = pc.Index(index_name).describe_index_stats()\n",
    "current_count = index_stats.get('total_vector_count', 0)\n",
    "\n",
    "print(f\"Current vectors in index: {current_count}\")\n",
    "\n",
    "if current_count == 0:\n",
    "    # First time: Create vectors\n",
    "    print(\"Creating vector store (first time)...\")\n",
    "    docsearch = PineconeVectorStore.from_documents(\n",
    "        documents=texts_chunk,\n",
    "        embedding=embedding,\n",
    "        index_name=index_name\n",
    "    )\n",
    "    print(f\"✅ Created {len(texts_chunk)} vectors\")\n",
    "else:\n",
    "    # Already has data: Just load it\n",
    "    print(\"Vector store exists. Loading...\")\n",
    "    docsearch = PineconeVectorStore.from_existing_index(\n",
    "        embedding=embedding,\n",
    "        index_name=index_name\n",
    "    )\n",
    "    print(f\"✅ Loaded existing store with {current_count} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64b0b59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded existing vector store\n"
     ]
    }
   ],
   "source": [
    "# OR load existing vector store\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    embedding=embedding,\n",
    "    index_name=index_name\n",
    ")\n",
    "print(\"✅ Loaded existing vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b77d0605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Retriever created\n"
     ]
    }
   ],
   "source": [
    "retriever = docsearch.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}\n",
    ")\n",
    "print(\"✅ Retriever created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f3d8477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 documents\n",
      "\n",
      "Doc 1: GALE ENCYCLOPEDIA OF MEDICINE 226\n",
      "Acne\n",
      "GEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 26...\n",
      "\n",
      "Doc 2: GALE ENCYCLOPEDIA OF MEDICINE 226\n",
      "Acne\n",
      "GEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 26...\n",
      "\n",
      "Doc 3: GALE ENCYCLOPEDIA OF MEDICINE 226\n",
      "Acne\n",
      "GEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 26...\n"
     ]
    }
   ],
   "source": [
    "# Test retrieval\n",
    "retrieved_docs = retriever.invoke(\"What is Acne?\")\n",
    "print(f\"Retrieved {len(retrieved_docs)} documents\")\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"\\nDoc {i}: {doc.page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fd44e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ab5d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# USE NEW MODEL\n",
    "chatModel = ChatGroq(\n",
    "    model_name=\"x\",\n",
    "    groq_api_key=GROQ_API_KEY,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"✅ Groq LLM initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c285db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Groq LLM initialized\n",
      "The provided context appears to be a table of contents from the \"GALE ENCYCLOPEDIA OF MEDICINE 2V\". It mentions the following:\n",
      "\n",
      "1. **Volume 5: T-Z**: This suggests that the encyclopedia covers topics starting from the letter T to Z, and this section starts on page 3237.\n",
      "2. **Organizations**: A section dedicated to listing organizations, which can be found starting on page 3603.\n",
      "3. **General Index**: A comprehensive index of the encyclopedia, starting on page 3625.\n",
      "\n",
      "These are the main items mentioned in the given context.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Use ONLY the following context to answer the question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer in a helpful and clear way.\n",
    "\"\"\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | chatModel\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "response = rag_chain.invoke(\"What is mentioned in the PDF?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "684cdc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Prompt created\n"
     ]
    }
   ],
   "source": [
    "system_prompt = (\n",
    "    \"You are a Medical assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "print(\"✅ Prompt created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de27f4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RAG chain ready!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "question_answer_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"input\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | chatModel\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "rag_chain = question_answer_chain\n",
    "\n",
    "print(\"✅ RAG chain ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "82ffb387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "Acromegaly is a disorder caused by the abnormal release of a chemical from the pituitary gland, leading to increased growth in bone and soft tissue. It results in various disturbances throughout the body. The specific chemical is not mentioned in the context, but it implies a hormonal imbalance affecting growth and development.\n"
     ]
    }
   ],
   "source": [
    "# Test the chatbot\n",
    "response = rag_chain.invoke(\"what is Acromegaly and gigantism?\")\n",
    "print(\"\\nAnswer:\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "interactive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: What are the symptoms of diabetes?\n",
      "A: The symptoms of diabetes include fatigue and an abnormally high level of glucose in the blood, also known as hyperglycemia. Additionally, if left untreated, diabetes can cause damage or failure to various body organs such as the eyes, kidneys, nerves, heart, and blood vessels. Early diagnosis is crucial to prevent these complications.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The symptoms of diabetes include fatigue and an abnormally high level of glucose in the blood, also known as hyperglycemia. Additionally, if left untreated, diabetes can cause damage or failure to various body organs such as the eyes, kidneys, nerves, heart, and blood vessels. Early diagnosis is crucial to prevent these complications.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ask_question(question):\n",
    "    response = rag_chain.invoke(question)\n",
    "    print(f\"\\nQ: {question}\")\n",
    "    print(f\"A: {response}\\n\")\n",
    "    return response\n",
    "\n",
    "# Try it!\n",
    "ask_question(\"What are the symptoms of diabetes?\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
