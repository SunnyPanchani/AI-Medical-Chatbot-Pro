{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Medical Chatbot Development Notebook\n",
    "## Using LangChain 1.0 + Groq + Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4646cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9efc022",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab041165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc92ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fcdc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modern imports - Compatible with LangChain 1.0+\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d10d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_files(data):\n",
    "    \"\"\"Load all PDF files from directory\"\"\"\n",
    "    loader = DirectoryLoader(data, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f78f067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDFs from data folder\n",
    "extracted_docs = load_pdf_files('data')\n",
    "print(f\"Loaded {len(extracted_docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b65aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def filter_to_minimal_docs(docs: List[Document]) -> List[Document]:\n",
    "    \"\"\"Keep only essential metadata\"\"\"\n",
    "    minimal_docs: List[Document] = []\n",
    "    for doc in docs:\n",
    "        src = doc.metadata.get('source')\n",
    "        minimal_docs.append(\n",
    "            Document(page_content=doc.page_content, metadata={'source': src})\n",
    "        )\n",
    "    return minimal_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aced9c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_docs = filter_to_minimal_docs(extracted_docs)\n",
    "print(f\"Filtered to {len(minimal_docs)} minimal documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9805f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(minimal_docs):\n",
    "    \"\"\"Split documents into chunks\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20\n",
    "    )\n",
    "    texts_chunk = text_splitter.split_documents(minimal_docs)\n",
    "    return texts_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02477dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_chunk = text_split(minimal_docs)\n",
    "print(f\"Split into {len(texts_chunk)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c5bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embeddings model\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def download_embeddings():\n",
    "    \"\"\"Initialize HuggingFace embeddings\"\"\"\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "    return embeddings\n",
    "\n",
    "embedding = download_embeddings()\n",
    "print(\"‚úÖ Embeddings model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db262a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test embeddings\n",
    "vectors = embedding.embed_query(\"Hello world\")\n",
    "print(f\"Vector dimension: {len(vectors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281c578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "print(\"‚úÖ Environment variables loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83bca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API keys from environment (SECURE WAY)\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "if not PINECONE_API_KEY:\n",
    "    print(\"‚ùå PINECONE_API_KEY not found\")\n",
    "else:\n",
    "    print(\"‚úÖ Pinecone API key loaded\")\n",
    "    \n",
    "if not GROQ_API_KEY:\n",
    "    print(\"‚ùå GROQ_API_KEY not found\")\n",
    "else:\n",
    "    print(\"‚úÖ Groq API key loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef078d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "print(\"‚úÖ Connected to Pinecone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1eeba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "index_name = \"medical-chatbot\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    print(f\"Creating index '{index_name}'...\")\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "    print(\"‚úÖ Index created\")\n",
    "else:\n",
    "    print(f\"‚úÖ Index '{index_name}' already exists\")\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ab676e",
   "metadata": {},
   "source": [
    "## Check if Documents Already Exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d68a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# Check if vectors already exist\n",
    "index_stats = pc.Index(index_name).describe_index_stats()\n",
    "current_count = index_stats.get('total_vector_count', 0)\n",
    "\n",
    "print(f\"Current vectors in index: {current_count}\")\n",
    "\n",
    "if current_count == 0:\n",
    "    # First time: Create vectors\n",
    "    print(\"Creating vector store (first time)...\")\n",
    "    docsearch = PineconeVectorStore.from_documents(\n",
    "        documents=texts_chunk,\n",
    "        embedding=embedding,\n",
    "        index_name=index_name\n",
    "    )\n",
    "    print(f\"‚úÖ Created {len(texts_chunk)} vectors\")\n",
    "else:\n",
    "    # Already has data: Just load it\n",
    "    print(\"Vector store exists. Loading...\")\n",
    "    docsearch = PineconeVectorStore.from_existing_index(\n",
    "        embedding=embedding,\n",
    "        index_name=index_name\n",
    "    )\n",
    "    print(f\"‚úÖ Loaded existing store with {current_count} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b0b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR load existing vector store\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    embedding=embedding,\n",
    "    index_name=index_name\n",
    ")\n",
    "print(\"‚úÖ Loaded existing vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77d0605",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}\n",
    ")\n",
    "print(\"‚úÖ Retriever created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3d8477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test retrieval\n",
    "retrieved_docs = retriever.invoke(\"What is Acne?\")\n",
    "print(f\"Retrieved {len(retrieved_docs)} documents\")\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"\\nDoc {i}: {doc.page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fd44e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ab5d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "chatModel = ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    groq_api_key=GROQ_API_KEY,\n",
    "    temperature=0.3,      # Balanced creativity vs accuracy\n",
    "    max_tokens=1024       # Allow longer, detailed responses\n",
    ")\n",
    "\n",
    "# Better retriever - get more context\n",
    "retriever = docsearch.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}  # Retrieve 5 documents instead of 3\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Optimized model initialized\")\n",
    "print(\"   Model: Llama 3.3 70B\")\n",
    "print(\"   Temperature: 0.3\")\n",
    "print(\"   Max tokens: 1024\")\n",
    "print(\"   Retrieval: Top 5 documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c285db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "system_prompt = \"\"\"You are an expert Medical Assistant with comprehensive knowledge of medical conditions, treatments, and healthcare.\n",
    "\n",
    "Your role is to provide detailed, accurate, and helpful answers based on the medical literature provided in the context.\n",
    "\n",
    "Guidelines for your responses:\n",
    "1. **Be Comprehensive**: Provide thorough explanations covering all relevant aspects\n",
    "2. **Be Structured**: Organize information logically (definition, causes, symptoms, treatment, etc.)\n",
    "3. **Be Clear**: Explain medical terms in understandable language\n",
    "4. **Be Accurate**: Only use information from the provided context\n",
    "5. **Be Helpful**: Anticipate follow-up questions and address them\n",
    "6. **Be Honest**: If information is missing from context, clearly state it\n",
    "\n",
    "Context from medical literature:\n",
    "{context}\n",
    "\n",
    "Provide a detailed, well-structured answer to the following question:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Enhanced medical prompt created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de27f4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    \"\"\"Format documents with clear structure\"\"\"\n",
    "    formatted = []\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        source = doc.metadata.get('source', 'Unknown')\n",
    "        content = doc.page_content.strip()\n",
    "        formatted.append(f\"[Document {i} - {source}]:\\n{content}\")\n",
    "    return \"\\n\\n\" + \"=\"*60 + \"\\n\\n\".join(formatted)\n",
    "\n",
    "print(\"‚úÖ Document formatter ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10da7ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"input\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | chatModel\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Optimized RAG chain ready!\")\n",
    "print(\"\\nImprovements:\")\n",
    "print(\"  ‚Ä¢ 5 source documents (more context)\")\n",
    "print(\"  ‚Ä¢ Enhanced prompt for deeper answers\")\n",
    "print(\"  ‚Ä¢ Better document formatting\")\n",
    "print(\"  ‚Ä¢ Llama 3.3 70B for best quality\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0801842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Dict\n",
    "\n",
    "def ask_medical_question(\n",
    "    question: str,\n",
    "    show_sources: bool = True,\n",
    "    show_timing: bool = True,\n",
    "    show_retrieved_docs: bool = False\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Ask a comprehensive medical question\n",
    "    \n",
    "    Args:\n",
    "        question: Your medical question\n",
    "        show_sources: Display sources used (default: True)\n",
    "        show_timing: Show response time (default: True)\n",
    "        show_retrieved_docs: Show full retrieved documents (default: False)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with answer and metadata\n",
    "    \"\"\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Header\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"üìã QUESTION: {question}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Get answer\n",
    "    print(\"ü§ñ Generating comprehensive answer...\\n\")\n",
    "    response = rag_chain.invoke(question)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Display answer with nice formatting\n",
    "    print(\"üí° DETAILED ANSWER:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(response)\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Show sources\n",
    "    if show_sources:\n",
    "        retrieved_docs = retriever.invoke(question)\n",
    "        print(f\"\\nüìö SOURCES CONSULTED ({len(retrieved_docs)} documents):\")\n",
    "        for i, doc in enumerate(retrieved_docs, 1):\n",
    "            source = doc.metadata.get('source', 'Unknown')\n",
    "            preview = doc.page_content[:200].replace('\\n', ' ').strip()\n",
    "            print(f\"\\n  [{i}] {source}\")\n",
    "            print(f\"      Preview: {preview}...\")\n",
    "            \n",
    "            if show_retrieved_docs:\n",
    "                print(f\"\\n      Full content:\\n{doc.page_content}\\n\")\n",
    "    \n",
    "    # Show timing\n",
    "    if show_timing:\n",
    "        print(f\"\\n‚è±Ô∏è  Response time: {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"answer\": response,\n",
    "        \"time\": elapsed_time\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Advanced question function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e8a021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_quick(question: str):\n",
    "    \"\"\"Get a quick, concise answer\"\"\"\n",
    "    quick_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a medical assistant. Answer briefly in 2-3 sentences.\\n\\nContext: {context}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ])\n",
    "    \n",
    "    quick_chain = (\n",
    "        {\"context\": retriever | format_docs, \"input\": RunnablePassthrough()}\n",
    "        | quick_prompt\n",
    "        | chatModel\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    print(f\"‚ùì {question}\")\n",
    "    response = quick_chain.invoke(question)\n",
    "    print(f\"üí° {response}\\n\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811ea606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_simple(question: str):\n",
    "    \"\"\"Get an easy-to-understand answer\"\"\"\n",
    "    simple_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a caring doctor. Explain in simple language without medical jargon.\\n\\nContext: {context}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ])\n",
    "    \n",
    "    simple_chain = (\n",
    "        {\"context\": retriever | format_docs, \"input\": RunnablePassthrough()}\n",
    "        | simple_prompt\n",
    "        | chatModel\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    print(f\"‚ùì {question}\")\n",
    "    response = simple_chain.invoke(question)\n",
    "    print(f\"üí° {response}\\n\")\n",
    "    return response\n",
    "\n",
    "print(\"‚úÖ Multiple question modes ready:\")\n",
    "print(\"   ‚Ä¢ ask_medical_question() - Detailed, comprehensive\")\n",
    "print(\"   ‚Ä¢ ask_quick()            - Brief, 2-3 sentences\")\n",
    "print(\"   ‚Ä¢ ask_simple()           - Easy language, no jargon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f942edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ask_medical_question(\n",
    "    \"What is acne? Explain its causes, symptoms, and treatment options in detail.\",\n",
    "    show_sources=True,\n",
    "    show_timing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616ad4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions = [\n",
    "    \"What is diabetes mellitus? Explain the types and management.\",\n",
    "    \"What are the main symptoms and treatment of hypertension?\",\n",
    "    \"Describe pneumonia, its causes, and how it's diagnosed.\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üß™ TESTING MULTIPLE QUESTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, q in enumerate(test_questions, 1):\n",
    "    print(f\"\\n[Question {i}/{len(test_questions)}]\\n\")\n",
    "    ask_medical_question(q, show_sources=False, show_timing=False)\n",
    "    print(\"\\n\" + \"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8755bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_chat():\n",
    "    \"\"\"Start interactive medical chatbot session\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üè• INTERACTIVE MEDICAL CHATBOT\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nAsk detailed medical questions. Type 'quit' to exit.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        question = input(\"‚ùì Your question: \").strip()\n",
    "        \n",
    "        if question.lower() in ['quit', 'exit', 'q', '']:\n",
    "            print(\"\\nüëã Session ended. Stay healthy!\")\n",
    "            break\n",
    "        \n",
    "        ask_medical_question(question, show_sources=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0f2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_answers(question: str):\n",
    "    \"\"\"Compare different answer modes side by side\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"üìä COMPARING ANSWER MODES\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    print(\"üîπ QUICK MODE (Concise):\")\n",
    "    print(\"-\" * 80)\n",
    "    ask_quick(question)\n",
    "    \n",
    "    print(\"\\nüîπ SIMPLE MODE (Patient-friendly):\")\n",
    "    print(\"-\" * 80)\n",
    "    ask_simple(question)\n",
    "    \n",
    "    print(\"\\nüîπ DETAILED MODE (Comprehensive):\")\n",
    "    print(\"-\" * 80)\n",
    "    ask_medical_question(question, show_sources=False, show_timing=False)\n",
    "\n",
    "# Test comparison\n",
    "compare_answers(\"What is asthma?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
